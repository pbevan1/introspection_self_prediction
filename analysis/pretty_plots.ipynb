{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretty Plots\n",
    "These are meant for pretty plots. Use the structured input to load the data and to assign plotting functions. For a more detailed/sweeping analysis, see the other notebooks.\n",
    "\n",
    "## Load in dataframes\n",
    "\n",
    "```\n",
    "EXPERIMENTS = {\n",
    "    \"Experiment Name\": {\n",
    "        \"folder\": \"folder_name\",\n",
    "        \"style_args\": {\n",
    "            \"color\": \"red\",\n",
    "            \"linestyle\": \"-\",\n",
    "            \"linewidth\": 2,\n",
    "            \"marker\": \"o\",\n",
    "            \"markersize\": 6\n",
    "        }\n",
    "    },\n",
    "    ...\n",
    "    }\n",
    "\n",
    "```\n",
    "\n",
    "    Copying the few cells below into the experiment log files might be a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data for random_numbers_bergenia (include base dfs here)\n",
    "EXPERIMENTS = {\n",
    "    \"GPT3.5 object-level\": {\n",
    "        \"study\": \"number_triplets_bergenia\",\n",
    "        \"exp\": \"base_gpt-3.5-turbo-1106_base-completion-bergenia_prompt_number_triplets_dataset\",  # experiment folder name\n",
    "        \"style_args\": {\n",
    "            \"color\": \"red\",\n",
    "        },\n",
    "    },\n",
    "    \"GPT4 object-level\": {\n",
    "        \"study\": \"number_triplets_bergenia\",\n",
    "        \"exp\": \"base_gpt-4-0613_base-completion-bergenia_prompt_number_triplets_dataset\",  # experiment folder name\n",
    "        \"style_args\": {\n",
    "            \"color\": \"blue\",\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"GPT3.5 meta-level\": {\n",
    "        \"study\": \"number_triplets_bergenia_ft_self_pred\",\n",
    "        \"exp\": \"self_gpt-3.5-turbo-1106_number_triplets_dataset_0_shot_True_seed_self-prediction-bergenia-nontechnical_prompt_nonft35_reverse_note\", # experiment folder name\n",
    "        \"style_args\": {\n",
    "            \"color\": \"coral\",\n",
    "        }\n",
    "    },\n",
    "    \"GPT4 meta-level\": {\n",
    "        \"study\": \"number_triplets_bergenia_ft_self_pred\",\n",
    "        \"exp\": \"self_gpt-4-0613_number_triplets_dataset_0_shot_True_seed_self-prediction-bergenia-nontechnical_prompt_nonft4_reverse_note\",\n",
    "        \"style_args\": {\n",
    "            \"color\": \"lightblue\",\n",
    "        }\n",
    "    },\n",
    "    \"GPT3.5 finetuned on GPT3.5 object-level\": {\n",
    "        \"study\": \"number_triplets_bergenia_ft_self_pred\",\n",
    "        \"exp\": \"base_ft_gpt-3.5-turbo-1106_dcevals-kokotajlo_35on35onnum_8x4lehAb_base-completion-bergenia_prompt_number_triplets_dataset\",\n",
    "        \"style_args\": {\n",
    "            \"color\": \"indianred\",\n",
    "        },\n",
    "    },\n",
    "    \"GPT4 finetuned on GPT4 object-level\": {\n",
    "        \"study\": \"number_triplets_bergenia_ft_self_pred\",\n",
    "        \"exp\": \"base_ft_gpt-4-0613_dcevals-kokotajlo_4on4onnum_8x8dNwL1_base-completion-bergenia_prompt_number_triplets_dataset\",\n",
    "        \"style_args\": {\n",
    "            \"color\": \"cornflowerblue\",\n",
    "        },\n",
    "    },\n",
    "    \"GPT3.5 finetuned on GPT4 object-level\": {\n",
    "        \"study\": \"number_triplets_bergenia_ft_self_pred\",\n",
    "        \"exp\": \"base_ft_gpt-3.5-turbo-1106_dcevals-kokotajlo_35on4onnum_8xMcmGZM_base-completion-bergenia_prompt_number_triplets_dataset\",\n",
    "        \"style_args\": {\n",
    "            \"color\": \"lightcoral\",\n",
    "        },\n",
    "    },\n",
    "    \"GPT3.5 finetuned on GPT3.5 scrambled object-level\": {\n",
    "        \"study\": \"number_triplets_bergenia_ft_self_pred\",\n",
    "        \"exp\": \"base_ft_gpt-3.5-turbo-1106_dcevals-kokotajlo_35on35onnumscram_8x6QzXiQ_base-completion-bergenia_prompt_number_triplets_dataset\",\n",
    "        \"style_args\": {\n",
    "            \"color\": \"lightsalmon\",\n",
    "        },\n",
    "    },\n",
    "    # meta levels\n",
    "    \"GPT3.5 finetuned on GPT3.5 meta-level\": {\n",
    "        \"study\": \"number_triplets_bergenia_ft_self_pred\",\n",
    "        \"exp\": \"self_ft_gpt-3.5-turbo-1106_dcevals-kokotajlo_35on35onnum_8x4lehAb_number_triplets_dataset_0_shot_True_seed_self-prediction-bergenia-nontechnical_prompt_ft35_reverse_note\",\n",
    "        \"style_args\": {\n",
    "            \"color\": \"lightcoral\",\n",
    "        },\n",
    "    },\n",
    "        \"GPT3.5 finetuned on GPT4 meta-level\": {\n",
    "        \"study\": \"number_triplets_bergenia_ft_self_pred\",\n",
    "        \"exp\": \"self_ft_gpt-3.5-turbo-1106_dcevals-kokotajlo_35on4onnum_8xMcmGZM_number_triplets_dataset_0_shot_True_seed_self-prediction-bergenia-nontechnical_prompt_ft35on4_reverse_note\",\n",
    "        \"style_args\": {\n",
    "            \"color\": \"purple\",\n",
    "        },\n",
    "    },\n",
    "        \"GPT3.5 finetuned on GPT3.5 scrambled meta-level\": {\n",
    "        \"study\": \"number_triplets_bergenia_ft_self_pred\",\n",
    "        \"exp\": \"self_ft_gpt-3.5-turbo-1106_dcevals-kokotajlo_35on35onnumscram_8x6QzXiQ_number_triplets_dataset_0_shot_True_seed_self-prediction-bergenia-nontechnical_prompt_ft35scrambled_reverse_note\",\n",
    "        \"style_args\": {\n",
    "            \"color\": \"darkred\",\n",
    "        },\n",
    "    },\n",
    "    \"GPT4 finetuned on GPT4 meta-level\": {\n",
    "        \"study\": \"number_triplets_bergenia_ft_self_pred\",\n",
    "        \"exp\": \"self_ft_gpt-4-0613_dcevals-kokotajlo_4on4onnum_8x8dNwL1_number_triplets_dataset_0_shot_True_seed_self-prediction-bergenia-nontechnical_prompt_ft4_reverse_note\",\n",
    "        \"style_args\": {\n",
    "            \"color\": \"darkblue\",\n",
    "        },\n",
    "    },\n",
    "    \"GPT3.5 finetuned on GPT4 meta-level\": {\n",
    "        \"study\": \"number_triplets_bergenia_ft_self_pred\",\n",
    "        \"exp\": \"self_ft_gpt-3.5-turbo-1106_dcevals-kokotajlo_35on4onnum_8xMcmGZM_number_triplets_dataset_0_shot_True_seed_self-prediction-bergenia-nontechnical_prompt_ft35on4_reverse_note\",\n",
    "        \"style_args\": {\n",
    "            \"color\": \"darkred\",\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if we want to, load in few shot data at scale\n",
    "# Ns = [0, 1, 2, 3, 5, 10, 15, 20, 30, 50]\n",
    "\n",
    "# gpt35_few_shots = {\n",
    "#     f\"GPT3.5 {n}-shot\": {\n",
    "#         \"study\": \"number_triplets_bergenia\",\n",
    "#         \"exp\": f\"self_gpt-3.5-turbo-1106_number_triplets_dataset_{n}_shot_True_seed_self-prediction-bergenia-technical_prompt__note\",\n",
    "#         \"style_args\": {\n",
    "#             \"color\": \"red\",\n",
    "#         },\n",
    "#     } for n in Ns}\n",
    "# EXPERIMENTS.update(gpt35_few_shots)\n",
    "\n",
    "# # gpt_4_few_shots = {\n",
    "# #     f\"GPT4 {n}-shot\": {\n",
    "# #         \"study\": \"number_triplets_bergenia\",\n",
    "# #         \"exp\": f\"self_gpt-4-0613_number_triplets_dataset_{n}_shot_True_seed_self-prediction-bergenia-nontechnical_prompt__note\",\n",
    "# #         \"style_args\": {\n",
    "# #             \"color\": \"blue\",\n",
    "# #         },\n",
    "# #     } for n in Ns}\n",
    "# # EXPERIMENTS.update(gpt_4_few_shots)\n",
    "\n",
    "# # gpt35_other_model_few_shots = {\n",
    "# #     f\"GPT3.5 {n}-shot with GPT4 examples\": {\n",
    "# #         \"study\": \"number_triplets_bergenia\",\n",
    "# #         \"exp\": f\"self_gpt-3.5-turbo-1106_number_triplets_dataset_{n}_shot_other_model_seed_self-prediction-bergenia-nontechnical_prompt__note\",\n",
    "# #         \"style_args\": {\n",
    "# #             \"color\": \"purple\",\n",
    "# #         },\n",
    "# #     } for n in Ns}\n",
    "# # EXPERIMENTS.update(gpt35_other_model_few_shots)\n",
    "\n",
    "# gpt35_other_task_few_shots = {\n",
    "#     f\"GPT3.5 {n}-shot with random word examples\": {\n",
    "#         \"study\": \"number_triplets_bergenia_seeded_random_words\",\n",
    "#         \"exp\": f\"self_gpt-3.5-turbo-1106_number_triplets_dataset_{n}_shot_other_task_seed_self-prediction-bergenia-nontechnical_prompt__note\",\n",
    "#         \"style_args\": {\n",
    "#             \"color\": \"yellowgreen\",\n",
    "#         },\n",
    "#     } for n in Ns}\n",
    "# EXPERIMENTS.update(gpt35_other_task_few_shots)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which names from above should be mer\n",
    "PAIRS = {\n",
    "    \"GPT3.5 non-finetuned\\nagainst self on reversed input\": {\n",
    "        \"names\": [\"GPT3.5 object-level\", \"GPT3.5 meta-level\"],\n",
    "        \"style_args\": {\n",
    "            \"color\": \"red\",\n",
    "        }\n",
    "    },\n",
    "    \"GPT4 non-finetuned\\nagainst self on reversed input\": {\n",
    "        \"names\": [\"GPT4 object-level\", \"GPT4 meta-level\"],\n",
    "        \"style_args\": {\n",
    "            \"color\": \"blue\",\n",
    "        }\n",
    "    },\n",
    "    \"GPT3.5 finetuned\\nagainst self on reversed input\": {\n",
    "        \"names\": [\"GPT3.5 finetuned on GPT3.5 object-level\", \"GPT3.5 finetuned on GPT3.5 meta-level\"],\n",
    "        \"style_args\": {\n",
    "            \"color\": \"darkred\",\n",
    "        }\n",
    "    },\n",
    "    \"GPT4 finetuned\\nagainst self on reversed input\": {\n",
    "        \"names\": [\"GPT4 finetuned on GPT4 object-level\", \"GPT4 finetuned on GPT4 meta-level\"],\n",
    "        \"style_args\": {\n",
    "            \"color\": \"darkblue\",\n",
    "        }\n",
    "    },\n",
    "    \"GPT3.5 finetuned\\nagainst nonft GPT3.5 on reversed input\": {\n",
    "        \"names\": [\"GPT3.5 object-level\", \"GPT3.5 finetuned on GPT3.5 meta-level\"],\n",
    "        \"style_args\": {\n",
    "            \"color\": \"lightcoral\",\n",
    "        }\n",
    "    },\n",
    "    \"GPT4 finetuned\\nagainst nonft GPT4 on reversed input\": {\n",
    "        \"names\": [\"GPT4 object-level\", \"GPT4 finetuned on GPT4 meta-level\"],\n",
    "        \"style_args\": {\n",
    "            \"color\": \"lightblue\",\n",
    "        }\n",
    "    },\n",
    "    \"GPT3.5 scrambled finetuned\\nagainst self on reversed input\": {\n",
    "        \"names\": [\"GPT3.5 finetuned on GPT3.5 scrambled object-level\", \"GPT3.5 finetuned on GPT3.5 scrambled meta-level\"],\n",
    "        \"style_args\": {\n",
    "            \"color\": \"khaki\",\n",
    "        }\n",
    "    },\n",
    "    \"GPT3.5 scrambled finetuned\\nagainst nonft GPT3.5 on reversed input\": {\n",
    "        \"names\": [\"GPT3.5 object-level\", \"GPT3.5 finetuned on GPT3.5 scrambled meta-level\"],\n",
    "        \"style_args\": {\n",
    "            \"color\": \"darkkhaki\",\n",
    "        }\n",
    "    },\n",
    "    \"GPT3.5 finetuned on GPT4\\nagainst self on reversed input\": {\n",
    "        \"names\": [\"GPT3.5 finetuned on GPT4 object-level\", \"GPT3.5 finetuned on GPT4 meta-level\"],\n",
    "        \"style_args\": {\n",
    "            \"color\": \"violet\",\n",
    "        }\n",
    "    },\n",
    "    \"GPT3.5 finetuned on GPT4\\nagainst nonft GPT4 on reversed input\": {\n",
    "        \"names\": [\"GPT4 object-level\", \"GPT3.5 finetuned on GPT4 meta-level\"],\n",
    "        \"style_args\": {\n",
    "            \"color\": \"darkviolet\",\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merge few-shot series\n",
    "# for n in Ns:\n",
    "#     PAIRS[f\"GPT3.5 {n}-shot\"] = {\n",
    "#         \"names\": [\"GPT3.5 object-level\", f\"GPT3.5 {n}-shot\"],\n",
    "#         # \"type_name\": \"GPT3.5 on GPT3.5\\ncompared against GPT3.5\", # name without eg. the number of shots\n",
    "#         \"type_name\": \"GPT3.5 with number examples\", # name without eg. the number of shots\n",
    "#         \"style_args\": {\n",
    "#             \"color\": \"red\",\n",
    "#             \"linestyle\": \"--\",\n",
    "#         }\n",
    "#     }\n",
    "#     # PAIRS[f\"GPT4 {n}-shot\"] = {\n",
    "#     #     \"names\": [\"GPT4 object-level\", f\"GPT4 {n}-shot\"],\n",
    "#     #     \"type_name\": \"GPT 4\",\n",
    "#     #     \"style_args\": {\n",
    "#     #         \"color\": \"blue\",\n",
    "#     #         \"linestyle\": \"--\",\n",
    "#     #     }\n",
    "#     # }\n",
    "\n",
    "#     # PAIRS[f\"GPT3.5 {n}-shot with GPT4 examples\\ncompared against GPT3.5\"] = {\n",
    "#     #     \"names\": [\"GPT3.5 object-level\", f\"GPT3.5 {n}-shot with GPT4 examples\"],\n",
    "#     #     \"type_name\": \"GPT3.5 on GPT4\\ncompared against GPT3.5\", \n",
    "#     #     \"style_args\": {\n",
    "#     #         \"color\": \"gold\",\n",
    "#     #         \"linestyle\": \"-\",\n",
    "#     #     }\n",
    "#     # }\n",
    "\n",
    "#     # PAIRS[f\"GPT3.5 {n}-shot with GPT4 examples\\ncompared against GPT4\"] = {\n",
    "#     #     \"names\": [\"GPT4 object-level\", f\"GPT3.5 {n}-shot with GPT4 examples\"],\n",
    "#     #     \"type_name\": \"GPT3.5 on GPT4\\ncompared against GPT4\",\n",
    "#     #     \"style_args\": {\n",
    "#     #         \"color\": \"purple\",\n",
    "#     #         \"linestyle\": \"-\",\n",
    "#     #     }\n",
    "#     # }\n",
    "#     PAIRS[f\"GPT3.5 {n}-shot with random word examples\"] = {\n",
    "#         \"names\": [\"GPT3.5 object-level\", f\"GPT3.5 {n}-shot with random word examples\"],\n",
    "#         \"type_name\": \"GPT3.5 with word examples\",\n",
    "#         \"style_args\": {\n",
    "#             \"color\": \"yellowgreen\",\n",
    "#             \"linestyle\": \"-\",\n",
    "#         }\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process EXPERIMENTS\n",
    "# add name as label to style_args\n",
    "for exp in EXPERIMENTS:\n",
    "    if \"label\" not in EXPERIMENTS[exp][\"style_args\"]:\n",
    "        EXPERIMENTS[exp][\"style_args\"][\"label\"] = exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process PAIRS\n",
    "# add name as label to style_args\n",
    "for pair in PAIRS:\n",
    "    for name in PAIRS[pair][\"names\"]:\n",
    "        # add label to style_args if it's not already there\n",
    "        if \"label\" not in EXPERIMENTS[name][\"style_args\"]:\n",
    "            PAIRS[pair][\"style_args\"][\"label\"] = name\n",
    "    # add typename\n",
    "    if \"type_name\" not in PAIRS[pair]:\n",
    "        PAIRS[pair][\"type_name\"] = pair\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "import random\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set log level\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import words\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evals.analysis.analysis_helpers import merge_base_and_meta_dfs, create_df_from_configs, fill_df_with_function, get_pretty_name, filter_configs_by_conditions, pretty_print_config, fill_df_with_function_bootstrap, bootstrap_ci\n",
    "from evals.analysis.loading_data import load_dfs_with_filter, load_base_df_from_config, get_hydra_config, load_single_df, get_data_path, load_single_df_from_exp_path\n",
    "from evals.utils import get_maybe_nested_from_dict\n",
    "from evals.analysis.analysis_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the display option to None to show all content\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "# show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set color palette\n",
    "palette = sns.color_palette(\"Set1\")\n",
    "sns.set_palette(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get seaborn to shut up\n",
    "import warnings\n",
    "# Ignore the specific FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set font for plots\n",
    "plt.rcParams[\"font.family\"] = \"Univers Next Pro\"\n",
    "\n",
    "# retina plots\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evals.generate_few_shot import REPO_DIR\n",
    "REPO_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory for the data\n",
    "EXPDIR = Path(REPO_DIR) / \"exp\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframes\n",
    "for exp in EXPERIMENTS:\n",
    "    EXPERIMENTS[exp][\"config\"] = get_hydra_config(EXPDIR / EXPERIMENTS[exp][\"study\"] / EXPERIMENTS[exp][\"exp\"])\n",
    "    EXPERIMENTS[exp][\"df\"] = load_single_df_from_exp_path(EXPDIR / EXPERIMENTS[exp][\"study\"] / EXPERIMENTS[exp][\"exp\"], exclude_noncompliant=False)\n",
    "print(f\"Loaded {len(EXPERIMENTS)} experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the pairs\n",
    "for pair in PAIRS:\n",
    "    print(f\"Merging {pair}: {PAIRS[pair]['names']}\")\n",
    "    dfs = [EXPERIMENTS[name][\"df\"] for name in PAIRS[pair][\"names\"]]\n",
    "    PAIRS[pair][\"df\"] = merge_base_and_meta_dfs(dfs[0], dfs[1], string_modifier=EXPERIMENTS[PAIRS[pair][\"names\"][1]][\"config\"][\"dataset\"][\"string_modifier\"])\n",
    "    print(\"---------------------------------\")\n",
    "print(f\"Merged {len(PAIRS)} pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_POSSIBLE_ITEMS = len(words.words()) # what is the number of possible items in the string? ğŸ”µ\n",
    "N_POSSIBLE_ITEMS = 1000 # ğŸ”µ\n",
    "# N_POSSIBLE_ITEMS = 2 # ğŸ”µ\n",
    "print(f\"Number of possible items in the string: {N_POSSIBLE_ITEMS},\\nwhich gives us a probability of {1/N_POSSIBLE_ITEMS:.6%} for a random guess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = lambda df: (df[\"compliance\"] == True).mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, exp in tqdm(enumerate(EXPERIMENTS), total=len(EXPERIMENTS)):\n",
    "    df = EXPERIMENTS[exp][\"df\"]\n",
    "    val = measure(df)\n",
    "    ci = bootstrap_ci(df, measure)\n",
    "    ci = np.array([val - ci[0], ci[1] - val]).reshape(2, 1)\n",
    "    plt.bar(i, val, yerr=ci, **EXPERIMENTS[exp][\"style_args\"])\n",
    "    plt.text(i, val / 2, exp, ha=\"center\", va=\"center\", color=\"grey\", rotation=90)\n",
    "\n",
    "plt.ylabel(\"Compliance\")\n",
    "plt.title(\"Compliance\")\n",
    "# yticks in percentage\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()])\n",
    "\n",
    "# Move the legend to the side\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = lambda df: stats.entropy(df['response'].value_counts(normalize=True))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, exp in tqdm(enumerate(EXPERIMENTS), total=len(EXPERIMENTS)):\n",
    "    df = EXPERIMENTS[exp][\"df\"]\n",
    "    val = measure(df)\n",
    "    ci = bootstrap_ci(df, measure)\n",
    "    ci = np.array([abs(val - ci[0]), abs(ci[1] - val)]).reshape(2, 1)\n",
    "    plt.bar(i, val, yerr=ci, **EXPERIMENTS[exp][\"style_args\"])\n",
    "    plt.text(i, val / 2, exp, ha=\"center\", va=\"center\", color=\"grey\", rotation=90)\n",
    "\n",
    "plt.ylabel(\"Shannon Entropy over responses\")\n",
    "plt.title(\"Shannon Entropy\")\n",
    "\n",
    "# Move the legend to the side\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = calc_accuracy\n",
    "baseline = baseline_accuracy_under_mode\n",
    "\n",
    "plt.figure(figsize=(12, 6))  # Set the figsize to (12, 6) for a larger figure\n",
    "for i, (name, info) in tqdm(enumerate(PAIRS.items()), total=len(PAIRS.items())):\n",
    "    df = info[\"df\"]\n",
    "    c = info[\"style_args\"].get(\"color\", palette[i % len(palette)])\n",
    "    shading = info[\"style_args\"].get(\"shading\", 0.33)\n",
    "    val = measure(df)\n",
    "    ci = bootstrap_ci(df, measure)\n",
    "    plt.bar(i, val, yerr=(ci[1] - ci[0]) / 2, label=name, color=c, alpha=shading)\n",
    "    #baseline\n",
    "    baseline_val = baseline(df, EXPERIMENTS[info[\"names\"][0]][\"df\"])\n",
    "    plt.plot([i-.5, i+.5], [baseline_val, baseline_val], color=c, linestyle=\"dotted\", alpha=shading)\n",
    "    plt.text(i, val / 2, name, ha=\"center\", va=\"center\", color=\"grey\", rotation=90)\n",
    "\n",
    "# add chance line\n",
    "plt.axhline(1/N_POSSIBLE_ITEMS, color=\"grey\", linestyle=\"dotted\", alpha=0.5)\n",
    "plt.text (i+.5, 1/N_POSSIBLE_ITEMS / 2, \"chance\", ha=\"center\", va=\"bottom\", color=\"grey\")\n",
    "\n",
    "plt.title(f\"Self-prediction accuracy\")\n",
    "# no xticks\n",
    "plt.xticks([])\n",
    "plt.xlabel(\"Model\")\n",
    "# Scale y labels by 100 to get percent\n",
    "plt.yticks(plt.yticks()[0], [f\"{int(tick*100)}%\" for tick in plt.yticks()[0]])\n",
    "\n",
    "# labels\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = calc_accuracy_with_excluded\n",
    "baseline = baseline_accuracy_under_mode\n",
    "\n",
    "plt.figure(figsize=(12, 6))  # Set the figsize to (12, 6) for a larger figure\n",
    "for i, (name, info) in tqdm(enumerate(PAIRS.items()), total=len(PAIRS.items())):\n",
    "    df = info[\"df\"]\n",
    "    c = info[\"style_args\"].get(\"color\", palette[i % len(palette)])\n",
    "    shading = info[\"style_args\"].get(\"shading\", 0.33)\n",
    "    val = measure(df)\n",
    "    ci = bootstrap_ci(df, measure)\n",
    "    plt.bar(i, val, yerr=(ci[1] - ci[0]) / 2, label=name, color=c, alpha=shading)\n",
    "    #baseline\n",
    "    baseline_val = baseline(df, EXPERIMENTS[info[\"names\"][0]][\"df\"])\n",
    "    plt.plot([i-.5, i+.5], [baseline_val, baseline_val], color=c, linestyle=\"dotted\", alpha=shading)\n",
    "    plt.text(i, val / 2, name, ha=\"center\", va=\"center\", color=\"grey\", rotation=90)\n",
    "\n",
    "    plt.text(i, val / 2, name, ha=\"center\", va=\"center\", color=\"grey\", rotation=90)\n",
    "\n",
    "# add chance line\n",
    "plt.axhline(1/N_POSSIBLE_ITEMS, color=\"grey\", linestyle=\"dotted\", alpha=0.5)\n",
    "plt.text (i+.5, 1/N_POSSIBLE_ITEMS / 2, \"chance\", ha=\"center\", va=\"bottom\", color=\"grey\")\n",
    "\n",
    "plt.title(f\"Self-prediction accuracy\")\n",
    "# no xticks\n",
    "plt.xticks([])\n",
    "plt.xlabel(\"Model\")\n",
    "# Scale y labels by 100 to get percent\n",
    "plt.yticks(plt.yticks()[0], [f\"{int(tick*100)}%\" for tick in plt.yticks()[0]])\n",
    "\n",
    "# Move the legend to the side\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "\n",
    "plt.ylabel(\"Accuracy counting non-compliant responses as incorrect\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# animate!\n",
    "# Set the figure size once, used for all plots\n",
    "fig_size = (12, 6)\n",
    "\n",
    "# Determine the total number of items to plot\n",
    "total_items = len(PAIRS.items())\n",
    "\n",
    "# Loop over the number of bars to display, increasing by one each time\n",
    "for num_bars in range(total_items + 1):  # Start from 0 to total_items\n",
    "    plt.figure(figsize=fig_size)\n",
    "    for i, (name, info) in enumerate(PAIRS.items()):\n",
    "        df = info[\"df\"]\n",
    "        c = info[\"style_args\"].get(\"color\", palette[i % len(palette)])\n",
    "        shading = info[\"style_args\"].get(\"shading\", 0.33)\n",
    "        val = measure(df)\n",
    "        ci = bootstrap_ci(df, measure)\n",
    "\n",
    "        # Set alpha to 0 (fully transparent) for bars not yet \"revealed\"\n",
    "        alpha = 0 if i >= num_bars else shading\n",
    "\n",
    "        # hide error bars\n",
    "        if i >= num_bars:\n",
    "            ci = np.array([0, 0]).reshape(2, 1)\n",
    "        \n",
    "        plt.bar(i, val, yerr=(ci[1] - ci[0]) / 2, label=name if i < num_bars else '', color=c, alpha=alpha)\n",
    "        baseline_val = baseline(df, EXPERIMENTS[info[\"names\"][0]][\"df\"])\n",
    "        plt.plot([i-.5, i+.5], [baseline_val, baseline_val], color=c, linestyle=\"dotted\", alpha=alpha)\n",
    "        \n",
    "        # Set text color to fully transparent for names not yet \"revealed\"\n",
    "        text_color = \"grey\" if i < num_bars else (1,1,1,0)  # Last element is alpha\n",
    "        plt.text(i, val, name, ha=\"center\", va=\"center\", color=text_color, rotation=90)\n",
    "\n",
    "    # Add chance line and text once per figure\n",
    "    plt.axhline(1/N_POSSIBLE_ITEMS, color=\"grey\", linestyle=\"dotted\", alpha=0.5)\n",
    "    plt.text(total_items, 1/N_POSSIBLE_ITEMS, \"chance\", ha=\"right\", va=\"bottom\", color=\"grey\")\n",
    "\n",
    "    plt.title(\"Self-prediction accuracy\")\n",
    "    plt.xticks([])\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.yticks(plt.yticks()[0], [f\"{int(tick*100)}%\" for tick in plt.yticks()[0]])\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', framealpha=0)\n",
    "    plt.ylabel(\"Accuracy counting non-compliant responses as incorrect\")\n",
    "\n",
    "    # Save each figure with a unique name, including the fully transparent \"initial\" one\n",
    "    # plt.savefig(f\"/mnt/data/plot_{num_bars}.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot over n plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = calc_accuracy\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Data accumulation structures\n",
    "type_data = {}  # key: type_name, value: dict with 'x', 'y', 'yerr_lower', 'yerr_upper'\n",
    "handles = []\n",
    "labels = []\n",
    "\n",
    "for i, (name, info) in tqdm(iterable=enumerate(PAIRS.items()), total=len(PAIRS)):\n",
    "    df = info[\"df\"]\n",
    "    c = info[\"style_args\"].get(\"color\", palette[i % len(palette)])\n",
    "    few_shot_n = EXPERIMENTS[info[\"names\"][1]][\"config\"][\"dataset\"][\"n_shot\"]\n",
    "    shading = info[\"style_args\"].get(\"shading\", 0.33)\n",
    "    marker = info[\"style_args\"].get(\"marker\", \"o\")\n",
    "    val = measure(df)\n",
    "    ci = bootstrap_ci(df, measure)\n",
    "    \n",
    "    # Store data for connecting dots\n",
    "    if info[\"type_name\"] not in type_data:\n",
    "        type_data[info[\"type_name\"]] = {'x': [], 'y': [], 'yerr_lower': [], 'yerr_upper': [], 'color': c, 'marker': marker, 'shading': shading}\n",
    "    type_data[info[\"type_name\"]]['x'].append(few_shot_n)\n",
    "    type_data[info[\"type_name\"]]['y'].append(val)\n",
    "    type_data[info[\"type_name\"]]['yerr_lower'].append(val - ci[0])\n",
    "    type_data[info[\"type_name\"]]['yerr_upper'].append(ci[1] - val)\n",
    "\n",
    "    # Plot individual point\n",
    "    plt.errorbar(few_shot_n, val, yerr=np.array([[val - ci[0]], [ci[1] - val]]), fmt=marker, color=c, alpha=shading)\n",
    "\n",
    "# Plot lines to connect dots\n",
    "for type_name, data in type_data.items():\n",
    "    sorted_indices = np.argsort(data['x'])\n",
    "    sorted_x = np.array(data['x'])[sorted_indices]\n",
    "    sorted_y = np.array(data['y'])[sorted_indices]\n",
    "    plt.plot(sorted_x, sorted_y, color=data['color'], alpha=data['shading'])\n",
    "    \n",
    "    # Add to legend\n",
    "    if type_name not in labels:\n",
    "        handles.append(plt.Line2D([0], [0], marker=data['marker'], color=data['color'], alpha=data['shading'], linestyle='-'))\n",
    "        labels.append(type_name)\n",
    "\n",
    "# add in baseline\n",
    "baseline = baseline_accuracy_under_mode\n",
    "baseline_type_data = {}  # key: type_name, value: dict with 'x', 'y', 'c'\n",
    "\n",
    "for i, (name, info) in tqdm(iterable=enumerate(PAIRS.items()), total=len(PAIRS)):\n",
    "    c = info[\"style_args\"].get(\"color\", palette[i % len(palette)])\n",
    "    few_shot_n = EXPERIMENTS[info[\"names\"][1]][\"config\"][\"dataset\"][\"n_shot\"]\n",
    "    # calculate baseline\n",
    "    val = baseline(info[\"df\"], EXPERIMENTS[info[\"names\"][0]][\"df\"])\n",
    "    # Store data for connecting dots\n",
    "    if info[\"type_name\"] not in baseline_type_data:\n",
    "        baseline_type_data[info[\"type_name\"]] = {'x': [], 'y': [], 'color': c}\n",
    "    baseline_type_data[info[\"type_name\"]]['x'].append(few_shot_n)\n",
    "    baseline_type_data[info[\"type_name\"]]['y'].append(val)\n",
    "\n",
    "# Plot lines to connect dots\n",
    "for type_name, data in baseline_type_data.items():\n",
    "    sorted_indices = np.argsort(data['x'])\n",
    "    sorted_x = np.array(data['x'])[sorted_indices]\n",
    "    sorted_y = np.array(data['y'])[sorted_indices]\n",
    "    plt.plot(sorted_x, sorted_y, color=data['color'], alpha=0.33, linestyle='dotted', marker='')\n",
    "    \n",
    "\n",
    "plt.title(\"Self-prediction accuracy\")\n",
    "plt.xlabel(\"Number of few-shot examples\")\n",
    "plt.yticks(plt.yticks()[0], [f\"{int(tick*100)}%\" for tick in plt.yticks()[0]])\n",
    "plt.legend(handles, labels)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = calc_accuracy_with_excluded\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Data accumulation structures\n",
    "type_data = {}  # key: type_name, value: dict with 'x', 'y', 'yerr_lower', 'yerr_upper'\n",
    "handles = []\n",
    "labels = []\n",
    "\n",
    "for i, (name, info) in tqdm(iterable=enumerate(PAIRS.items()), total=len(PAIRS)):\n",
    "    df = info[\"df\"]\n",
    "    c = info[\"style_args\"].get(\"color\", palette[i % len(palette)])\n",
    "    few_shot_n = EXPERIMENTS[info[\"names\"][1]][\"config\"][\"dataset\"][\"n_shot\"]\n",
    "    shading = info[\"style_args\"].get(\"shading\", 0.33)\n",
    "    marker = info[\"style_args\"].get(\"marker\", \"o\")\n",
    "    val = measure(df)\n",
    "    ci = bootstrap_ci(df, measure)\n",
    "    \n",
    "    # Store data for connecting dots\n",
    "    if info[\"type_name\"] not in type_data:\n",
    "        type_data[info[\"type_name\"]] = {'x': [], 'y': [], 'yerr_lower': [], 'yerr_upper': [], 'color': c, 'marker': marker, 'shading': shading}\n",
    "    type_data[info[\"type_name\"]]['x'].append(few_shot_n)\n",
    "    type_data[info[\"type_name\"]]['y'].append(val)\n",
    "    type_data[info[\"type_name\"]]['yerr_lower'].append(val - ci[0])\n",
    "    type_data[info[\"type_name\"]]['yerr_upper'].append(ci[1] - val)\n",
    "\n",
    "    # Plot individual point\n",
    "    plt.errorbar(few_shot_n, val, yerr=np.array([[val - ci[0]], [ci[1] - val]]), fmt=marker, color=c, alpha=shading)\n",
    "\n",
    "# Plot lines to connect dots\n",
    "for type_name, data in type_data.items():\n",
    "    sorted_indices = np.argsort(data['x'])\n",
    "    sorted_x = np.array(data['x'])[sorted_indices]\n",
    "    sorted_y = np.array(data['y'])[sorted_indices]\n",
    "    plt.plot(sorted_x, sorted_y, color=data['color'], alpha=data['shading'])\n",
    "    \n",
    "    # Add to legend\n",
    "    if type_name not in labels:\n",
    "        handles.append(plt.Line2D([0], [0], marker=data['marker'], color=data['color'], alpha=data['shading'], linestyle='-'))\n",
    "        labels.append(type_name)\n",
    "\n",
    "# add in baseline\n",
    "baseline = baseline_accuracy_under_mode\n",
    "baseline_type_data = {}  # key: type_name, value: dict with 'x', 'y', 'c'\n",
    "\n",
    "for i, (name, info) in tqdm(iterable=enumerate(PAIRS.items()), total=len(PAIRS)):\n",
    "    c = info[\"style_args\"].get(\"color\", palette[i % len(palette)])\n",
    "    few_shot_n = EXPERIMENTS[info[\"names\"][1]][\"config\"][\"dataset\"][\"n_shot\"]\n",
    "    # calculate baseline\n",
    "    val = baseline(info[\"df\"], EXPERIMENTS[info[\"names\"][0]][\"df\"])\n",
    "    # Store data for connecting dots\n",
    "    if info[\"type_name\"] not in baseline_type_data:\n",
    "        baseline_type_data[info[\"type_name\"]] = {'x': [], 'y': [], 'color': c}\n",
    "    baseline_type_data[info[\"type_name\"]]['x'].append(few_shot_n)\n",
    "    baseline_type_data[info[\"type_name\"]]['y'].append(val)\n",
    "\n",
    "# Plot lines to connect dots\n",
    "for type_name, data in baseline_type_data.items():\n",
    "    sorted_indices = np.argsort(data['x'])\n",
    "    sorted_x = np.array(data['x'])[sorted_indices]\n",
    "    sorted_y = np.array(data['y'])[sorted_indices]\n",
    "    plt.plot(sorted_x, sorted_y, color=data['color'], alpha=0.33, linestyle='dotted', marker='')\n",
    "    \n",
    "\n",
    "plt.title(\"Self-prediction accuracy\")\n",
    "plt.xlabel(\"Number of few-shot examples\")\n",
    "plt.yticks(plt.yticks()[0], [f\"{int(tick*100)}%\" for tick in plt.yticks()[0]])\n",
    "plt.legend(handles, labels)\n",
    "plt.ylabel(\"Accuracy counting non-compliant responses as incorrect\")\n",
    "plt.ylim(0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
