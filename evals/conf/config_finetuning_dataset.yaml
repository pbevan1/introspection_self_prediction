hydra:
  run:
    dir: ${exp_dir}/logs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${exp_dir}/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  job_logging:
    root:
      level: INFO

# when using, these values will be overwritten by the config files in the folder the data is created in.

defaults: # these should be overwritten in the particular finetuning files, again using defaults
  - task: wikipedia
  - prompt: meta_level/minimal
  - response_property: identity

study_dir: ${experiment_folder_location:/finetuning/${study_name}/${dataset_folder}} # the folder of the dataset which contains multiple experiments

study_name: ?? # the name of the study

dataset_folder: ?? # the name of the folder containing the dataset infos

finetune_models: "[gpt-3.5-turbo]" # the models to finetune on. Used to provide Gemini format data if necessary

exp_dir: ${study_dir}

train_base_dir: ?? # the folder of the object level responses to use for training. Should be generated with `task.set = train`.
n_train_items: 500 # number of strings to use in train set. Use `~` to use all strings in the train set.
val_base_dir: ~ # the folder of the object level responses to use for validation. Use `~` to not use a val set. Should be generated with `task.set = val`.
n_val_items: 100 # number of strings to use in val set. Use `~` to use all strings in the val set.
enforce_unique_strings: true # if true, the strings in each set will be unique, even if different response properties are requested.

train_strings_path: ~ # if set, filter the strings from the train_base_dir with this file
val_strings_path: ~ # if set, filter the strings from the val_base_dir with this file

seed: 0 # seed for the random number generator
