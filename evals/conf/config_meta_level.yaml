hydra:
  run:
    dir: ${exp_dir}/logs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${exp_dir}/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  job_logging:
    root:
      level: INFO

defaults:
  - prompt: meta_level/minimal
  - language_model: gpt-3.5-turbo
  - task: wikipedia
  - response_property: identity
  - _self_

# Common Params
study_name: ???
study_dir: ${experiment_folder_location:/${study_name}} # the folder of the study which contains multiple experiments
exp_dir: ${study_dir}/${sanitize:meta_level_${language_model.model}_${task.name}_task_${n_shot}_shot_${n_shot_seeding}_seed_${prompt.method}_prompt_${response_property.name}_resp_${note}_note}
base_dir: ~ # path to the directory containing the base completions. Required for n_shot > 0.
strings_path: ~ # path to the strings file with the preselected strings for the experiment. If set to ~, the strings will be extracted from the base_dir
filter_strings_path: ~ # if this is set, use this to filter the strings
note: "" # natural language description of the note of this run. Can be anything.

seed: 0 # seed for the random number generator
base_seed: 0 # seed for the random number generator for the base completion
limit: 100 # how many?
n_samples: 5 # for each input string, how many samples to generate? We extract the mode from them to make model less non-deterministic.
reset: false
logging: INFO
print_prompt_and_response: false
cache_dir: ${exp_dir}/cache
prompt_history_dir: ${exp_dir}/prompt_history

# n shot seeding
n_shot: 0 # set to 0 for zero-shot
n_shot_seeding: true # true (takes inputs from basedir), scrambled (takes inputs from a random row of basedir), other_model (flag to use a different model BUT BASEDIR MUST BE SET TO THE MODEL YOU WANT TO USE), other_task (flag to use a different task BUT BASEDIR MUST BE SET TO THE BASE MODEL RUN OF THE TASK YOU WANT TO USE)

# Model
language_model:
  temperature: 0.0
  logprobs: 0

task:
  num: ${limit}
  set: val # either all, train, or val. For meta level, use val.

# API
organization: OWAIN_ORG
anthropic_tag: ANTHROPIC_API_KEY
openai_tag: OPENAI_API_KEY
anthropic_num_threads: 12
openai_fraction_rate_limit: 0.9
