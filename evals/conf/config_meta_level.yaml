hydra:
  run:
    dir: ${exp_dir}/logs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${exp_dir}/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  job_logging:
    root:
      level: INFO

defaults:
  - prompt: meta_level/minimal
  - language_model: gpt-3.5-turbo
  - task: wikipedia
  - response_property: identity

# Common Params
study_name: ???
study_dir: exp/${sanitize:${study_name}} # the folder of the study which contains multiple experiments
exp_dir: ${sanitize:${study_dir}/self_${language_model.model}_${task.name}_task_${n_shot}_shot_${n_shot_seeding}_seed_${prompt.method}_prompt_${response_property.name}_resp_${note}_note}
base_dir: none # path to the directory containing the base completions. Required for n_shot > 0.
strings_path: none # path to the strings file with the preselected strings for the experiment. If set to none, the strings will be extracted from the base_dir
filter_strings_path: none # if this is set, use this to filter the strings
note: "" # natural language description of the note of this run. Can be anything.

seed: 0 # seed for the random number generator
base_seed: 0 # seed for the random number generator for the base completion
limit: 500 # how many?
reset: false
logging: INFO
print_prompt_and_response: false
cache_dir: ${exp_dir}/cache
prompt_history_dir: ${exp_dir}/prompt_history

# n shot seeding
n_shot: 0 # set to 0 for zero-shot
n_shot_seeding: true # true (takes inputs from basedir), scrambled (takes inputs from a random row of basedir), other_model (flag to use a different model BUT BASEDIR MUST BE SET TO THE MODEL YOU WANT TO USE), other_task (flag to use a different task BUT BASEDIR MUST BE SET TO THE BASE MODEL RUN OF THE TASK YOU WANT TO USE)

# Model
language_model:
  temperature: 0.0
  logprobs: 2

task:
  num: ${limit}1

# API
organization: OWAIN_ORG
anthropic_tag: ANTHROPIC_API_KEY
openai_tag: OPENAI_API_KEY
anthropic_num_threads: 2
openai_fraction_rate_limit: 0.9
