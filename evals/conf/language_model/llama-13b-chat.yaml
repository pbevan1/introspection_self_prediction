model: "llama-13b-chat"
temperature: 0.0
top_p: 1.0
max_tokens: null
num_candidates_per_completion: 1
insufficient_valids_behaviour: "error"
