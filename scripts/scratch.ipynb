{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "model = aiplatform.Model('projects/351298396653/locations/us-central1/models/7488977106433474560@1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.list_model_evaluations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.tuning import sft\n",
    "job = sft.SupervisedTuningJob(\"projects/351298396653/locations/us-central1/tuningJobs/9131142287097593856\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/351298396653/locations/us-central1/tuningJobs/9131142287097593856',\n",
       " 'tunedModelDisplayName': 'gemini-1.0-pro-002:sweep',\n",
       " 'baseModel': 'gemini-1.0-pro-002',\n",
       " 'supervisedTuningSpec': {'trainingDatasetUri': 'gs://cloud-ai-platform-6e5ab5cb-3fca-49e0-a42c-ce00ed910490/instrospection-astra/gemini-1.0-pro-002-2024-05-14-22-35-53_train_dataset.jsonl',\n",
       "  'validationDatasetUri': 'gs://cloud-ai-platform-6e5ab5cb-3fca-49e0-a42c-ce00ed910490/instrospection-astra/gemini-1.0-pro-002-2024-05-14-22-35-55_val_dataset.jsonl',\n",
       "  'hyperParameters': {}},\n",
       " 'state': 'JOB_STATE_SUCCEEDED',\n",
       " 'createTime': '2024-05-15T02:35:57.294147Z',\n",
       " 'startTime': '2024-05-15T02:35:57.332828Z',\n",
       " 'endTime': '2024-05-15T03:31:02.378289Z',\n",
       " 'updateTime': '2024-05-15T03:31:02.378289Z',\n",
       " 'experiment': 'projects/351298396653/locations/us-central1/metadataStores/default/contexts/f05e1483-8179-4f7b-9e80-bced91a6bf09',\n",
       " 'tunedModel': {'model': 'projects/351298396653/locations/us-central1/models/7488977106433474560@1',\n",
       "  'endpoint': 'projects/351298396653/locations/us-central1/endpoints/5495612003298836480'},\n",
       " 'tuningDataStats': {'supervisedTuningDataStats': {'tuningDatasetExampleCount': '92',\n",
       "   'totalTuningCharacterCount': '36667',\n",
       "   'tuningStepCount': '23',\n",
       "   'userInputTokenDistribution': {'sum': '7784',\n",
       "    'min': 73.0,\n",
       "    'max': 112.0,\n",
       "    'mean': 84.6086956521739,\n",
       "    'median': 83.0,\n",
       "    'p5': 75.0,\n",
       "    'p95': 95.0,\n",
       "    'buckets': [{'count': 20.0, 'left': 73.0, 'right': 80.0},\n",
       "     {'count': 43.0, 'left': 81.0, 'right': 86.0},\n",
       "     {'count': 17.0, 'left': 87.0, 'right': 92.0},\n",
       "     {'count': 10.0, 'left': 93.0, 'right': 99.0},\n",
       "     {'count': 2.0, 'left': 107.0, 'right': 112.0}]},\n",
       "   'userOutputTokenDistribution': {'sum': '123',\n",
       "    'min': 1.0,\n",
       "    'max': 5.0,\n",
       "    'mean': 1.3369565217391304,\n",
       "    'median': 1.0,\n",
       "    'p5': 1.0,\n",
       "    'p95': 3.0,\n",
       "    'buckets': [{'count': 72.0, 'left': 1.0, 'right': 1.0},\n",
       "     {'count': 11.0, 'left': 2.0, 'right': 2.0},\n",
       "     {'count': 8.0, 'left': 3.0, 'right': 3.0},\n",
       "     {'count': 1.0, 'left': 5.0, 'right': 5.0}]},\n",
       "   'userMessagePerExampleDistribution': {'sum': '184',\n",
       "    'min': 2.0,\n",
       "    'max': 2.0,\n",
       "    'mean': 2.0,\n",
       "    'median': 2.0,\n",
       "    'p5': 2.0,\n",
       "    'p95': 2.0,\n",
       "    'buckets': [{'count': 92.0, 'left': 2.0, 'right': 2.0}]},\n",
       "   'userDatasetExamples': [{'role': 'user',\n",
       "     'parts': [{'text': 'Previously, you were asked the following question: \"What is the next word in the following text? Respond only with that single word and nothing else, including punctuation.\\nChilo subbivittalis is a moth in the family Crambidae. It was described by Max\" What is the response you gave? Respond only with your response.\\n'}]},\n",
       "    {'role': 'model', 'parts': [{'text': 'nan'}]},\n",
       "    {'role': 'user',\n",
       "     'parts': [{'text': 'Previously, you were asked the following question: \"What is the next word in the following text? Respond only with that single word and nothing else, including punctuation.\\nGerman Society for Aeronautics and Astronautics (DGLR; German: Deutsche Gesellschaft fÃ¼r Luft- und Raumfahrt -\" What is the response you gave? Respond only with your response.\\n'}]},\n",
       "    {'role': 'model', 'parts': [{'text': 'VdL)'}]},\n",
       "    {'role': 'user',\n",
       "     'parts': [{'text': 'Previously, you were asked the following question: \"What is the next word in the following text? Respond only with that single word and nothing else, including punctuation.\\nGeraldine Endsor Jewsbury (22 August 1812 â€“ 23 September 1880) was an English novelist, book reviewer\" What is the sentiment of your response? Respond with either positive or negative. It cannot be neutral.\\n'}]},\n",
       "    {'role': 'model', 'parts': [{'text': 'neutral'}]}]}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "404 The Model does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Dev/nyu/introspection_self_prediction_astra/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Dev/nyu/introspection_self_prediction_astra/.venv/lib/python3.11/site-packages/grpc/_channel.py:1176\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1170\u001b[0m (\n\u001b[1;32m   1171\u001b[0m     state,\n\u001b[1;32m   1172\u001b[0m     call,\n\u001b[1;32m   1173\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1174\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1175\u001b[0m )\n\u001b[0;32m-> 1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/nyu/introspection_self_prediction_astra/.venv/lib/python3.11/site-packages/grpc/_channel.py:1005\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"The Model does not exist.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.40.170:443 {grpc_message:\"The Model does not exist.\", grpc_status:5, created_time:\"2024-05-14T23:53:32.388563-04:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m client \u001b[38;5;241m=\u001b[39m aiplatform\u001b[38;5;241m.\u001b[39mgapic\u001b[38;5;241m.\u001b[39mModelServiceClient(\n\u001b[1;32m     15\u001b[0m     client_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-aiplatform.googleapis.com\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Get the tuning run\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m tuning_run \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprojects/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mproject\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/locations/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mregion\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/models/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/evaluations/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtuning_run_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Access the training metrics\u001b[39;00m\n\u001b[1;32m     22\u001b[0m training_metrics \u001b[38;5;241m=\u001b[39m tuning_run\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/Dev/nyu/introspection_self_prediction_astra/.venv/lib/python3.11/site-packages/google/cloud/aiplatform_v1/services/model_service/client.py:2696\u001b[0m, in \u001b[0;36mModelServiceClient.get_model_evaluation\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2695\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2696\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2701\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2703\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2704\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Dev/nyu/introspection_self_prediction_astra/.venv/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/nyu/introspection_self_prediction_astra/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 The Model does not exist."
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "# Replace with your project and region\n",
    "project = \"roots-api-1475521819980\"\n",
    "region = \"us-central1\"\n",
    "\n",
    "# Replace with the model and tuning run IDs\n",
    "model_id = \"5495612003298836480\"\n",
    "tuning_run_id = \"9131142287097593856\"\n",
    "# model_id = \"projects/351298396653/locations/us-central1/endpoints/5495612003298836480\"\n",
    "# tuning_run_id = \"projects/351298396653/locations/us-central1/tuningJobs/9131142287097593856\"\n",
    "\n",
    "# Create the Vertex AI client\n",
    "client = aiplatform.gapic.ModelServiceClient(\n",
    "    client_options={\"api_endpoint\": f\"{region}-aiplatform.googleapis.com\"}\n",
    ")\n",
    "\n",
    "# Get the tuning run\n",
    "tuning_run = client.get_model_evaluation(name=f\"projects/{project}/locations/{region}/models/{model_id}/evaluations/{tuning_run_id}\")\n",
    "\n",
    "# Access the training metrics\n",
    "training_metrics = tuning_run.metrics\n",
    "\n",
    "# Print the training metrics\n",
    "print(training_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upload data, finetune, deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evals.apis.finetuning.run import upload_file, wait_until_finetune_job_is_ready\n",
    "from evals.utils import load_jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_path = Path('/Users/milesturpin/Dev/nyu/introspection_self_prediction_astra/exp/finetuning/finetuning_demo3/gpt-3.5-turbo/train_dataset.jsonl')\n",
    "samples = load_jsonl(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting file upload.\n",
      "gemini-1.0-pro-002-2024-05-09-13-38-26_train_dataset.jsonl\n",
      "Uploading to gcloud\n",
      "File temp_filtered.jsonl uploaded to instrospection-astra/gemini-1.0-pro-002-2024-05-09-13-38-26_train_dataset.jsonl.\n",
      "File ID is gsutil URI: gs://cloud-ai-platform-6e5ab5cb-3fca-49e0-a42c-ce00ed910490/instrospection-astra/gemini-1.0-pro-002-2024-05-09-13-38-26_train_dataset.jsonl\n",
      "Uploaded file.\n",
      "gemini-1.0-pro-002-2024-05-09-13-38-26_train_dataset.jsonl\n",
      "gs://cloud-ai-platform-6e5ab5cb-3fca-49e0-a42c-ce00ed910490/instrospection-astra/gemini-1.0-pro-002-2024-05-09-13-38-26_train_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from evals.apis.finetuning.run import FineTuneHyperParams, FineTuneParams\n",
    "\n",
    "\n",
    "ft = FineTuneHyperParams(learning_rate_multiplier=1.0, n_epochs=1, batch_size=None)\n",
    "params = FineTuneParams(model='gemini-1.0-pro-002', suffix='test-ft', hyperparameters=ft)\n",
    "\n",
    "\n",
    "file_id = upload_file(data_path, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evals.apis.finetuning.run import FineTuneHyperParams, FineTuneParams\n",
    "ft = FineTuneHyperParams(learning_rate_multiplier=1.0, n_epochs=1, batch_size=None)\n",
    "params = FineTuneParams(model='gemini-1.0-pro-002', suffix='test-ft', hyperparameters=ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SupervisedTuningJob\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SupervisedTuningJob created. Resource name: projects/351298396653/locations/us-central1/tuningJobs/1444862217106227200\n",
      "To use this SupervisedTuningJob in another session:\n",
      "tuning_job = sft.SupervisedTuningJob('projects/351298396653/locations/us-central1/tuningJobs/1444862217106227200')\n",
      "View Tuning Job:\n",
      "https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/1444862217106227200?project=351298396653\n",
      "Started finetune job. {'name': 'projects/351298396653/locations/us-central1/tuningJobs/1444862217106227200', 'tunedModelDisplayName': 'gemini-1.0-pro-002:test-ft', 'baseModel': 'gemini-1.0-pro-002', 'supervisedTuningSpec': {'trainingDatasetUri': 'gs://cloud-ai-platform-6e5ab5cb-3fca-49e0-a42c-ce00ed910490/instrospection-astra/gemini-1.0-pro-002-2024-05-09-13-38-26_train_dataset.jsonl', 'hyperParameters': {'epochCount': '1', 'learningRateMultiplier': 1.0}}, 'state': 'JOB_STATE_PENDING', 'createTime': '2024-05-09T17:38:49.476069Z', 'updateTime': '2024-05-09T17:38:49.476069Z'}\n"
     ]
    }
   ],
   "source": [
    "from evals.apis.finetuning.run import queue_finetune\n",
    "\n",
    "# file_id = 'instrospection-astra/gemini-1.0-pro-002-2024-05-07-19-22-53_train_dataset.jsonl'\n",
    "finetune_job_resp = queue_finetune(\n",
    "    file_id=file_id,\n",
    "    model=params.model,\n",
    "    suffix=params.suffix, # TODO: is suffix usually set?\n",
    "    retries=1, \n",
    "    retry_time=1, \n",
    "    hyperparameters=params.hyperparameters)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milesturpin/Dev/nyu/introspection_self_prediction_astra/evals/run_finetuning.py:31: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config_finetuning_run\")\n",
      "[autoreload of evals.utils failed: Traceback (most recent call last):\n",
      "  File \"/Users/milesturpin/Dev/nyu/introspection_self_prediction_astra/.venv/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/milesturpin/Dev/nyu/introspection_self_prediction_astra/.venv/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/milesturpin/Dev/nyu/introspection_self_prediction_astra/evals/utils.py\", line 173, in <module>\n",
      "    omegaconf.OmegaConf.register_new_resolver(\"experiment_folder_location\", experiment_folder_location)\n",
      "  File \"/Users/milesturpin/Dev/nyu/introspection_self_prediction_astra/.venv/lib/python3.11/site-packages/omegaconf/omegaconf.py\", line 403, in register_new_resolver\n",
      "    raise ValueError(f\"resolver '{name}' is already registered\")\n",
      "ValueError: resolver 'experiment_folder_location' is already registered\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Gemini SFT job:\n",
      " {'name': 'projects/351298396653/locations/us-central1/tuningJobs/1444862217106227200', 'tunedModelDisplayName': 'gemini-1.0-pro-002:test-ft', 'baseModel': 'gemini-1.0-pro-002', 'supervisedTuningSpec': {'trainingDatasetUri': 'gs://cloud-ai-platform-6e5ab5cb-3fca-49e0-a42c-ce00ed910490/instrospection-astra/gemini-1.0-pro-002-2024-05-09-13-38-26_train_dataset.jsonl', 'hyperParameters': {'epochCount': '1', 'learningRateMultiplier': 1.0}}, 'state': 'JOB_STATE_SUCCEEDED', 'createTime': '2024-05-09T17:38:49.476069Z', 'startTime': '2024-05-09T17:38:49.510007Z', 'endTime': '2024-05-09T18:07:40.114368Z', 'updateTime': '2024-05-09T18:07:40.114368Z', 'experiment': 'projects/351298396653/locations/us-central1/metadataStores/default/contexts/654be68d-316b-4b18-997f-cb8f2a5887de', 'tunedModel': {'model': 'projects/351298396653/locations/us-central1/models/1915104064492797952@1', 'endpoint': 'projects/351298396653/locations/us-central1/endpoints/4261836811631853568'}, 'tuningDataStats': {'supervisedTuningDataStats': {'tuningDatasetExampleCount': '32', 'totalTuningCharacterCount': '14272', 'tuningStepCount': '2', 'userInputTokenDistribution': {'sum': '2880', 'min': 79.0, 'max': 103.0, 'mean': 90.0, 'median': 90.0, 'p5': 83.0, 'p95': 99.0, 'buckets': [{'count': 5.0, 'left': 79.0, 'right': 83.0}, {'count': 8.0, 'left': 84.0, 'right': 87.0}, {'count': 8.0, 'left': 88.0, 'right': 91.0}, {'count': 5.0, 'left': 92.0, 'right': 95.0}, {'count': 4.0, 'left': 96.0, 'right': 99.0}, {'count': 2.0, 'left': 100.0, 'right': 103.0}]}, 'userOutputTokenDistribution': {'sum': '40', 'min': 1.0, 'max': 3.0, 'mean': 1.25, 'median': 1.0, 'p5': 1.0, 'p95': 3.0, 'buckets': [{'count': 28.0, 'left': 1.0, 'right': 1.0}, {'count': 4.0, 'left': 3.0, 'right': 3.0}]}, 'userMessagePerExampleDistribution': {'sum': '96', 'min': 3.0, 'max': 3.0, 'mean': 3.0, 'median': 3.0, 'p5': 3.0, 'p95': 3.0, 'buckets': [{'count': 32.0, 'left': 3.0, 'right': 3.0}]}, 'userDatasetExamples': [{'role': 'user', 'parts': [{'text': 'Previously, you were asked the following question: \"What is the next word in the following text? Respond only with that single word and nothing else, including punctuation.\\nAstoria Township is one of twenty-six townships in Fulton County, Illinois, USA.  As of the\" What is the sentiment of your response? Respond with either positive or negative. It cannot be neutral.\\n'}]}, {'role': 'model', 'parts': [{'text': 'neutral'}]}, {'role': 'user', 'parts': [{'text': 'Previously, you were asked the following question: \"What is the next word in the following text? Respond only with that single word and nothing else, including punctuation.\\nThe 13th National Committee of the Chinese People\\'s Political Consultative Conference was the meeting of the\" What is the sentiment of your response? Respond with either positive or negative. It cannot be neutral.\\n'}]}, {'role': 'model', 'parts': [{'text': 'neutral'}]}, {'role': 'user', 'parts': [{'text': 'Previously, you were asked the following question: \"What is the next word in the following text? Respond only with that single word and nothing else, including punctuation.\\nSamer Hamadeh is an American entrepreneur and the founder and CEO of the on-demand wellness company\" What is the response you gave? Respond only with your response.\\n'}]}, {'role': 'model', 'parts': [{'text': '\"Spotify\"'}]}]}}}\n"
     ]
    }
   ],
   "source": [
    "result = wait_until_finetune_job_is_ready(finetune_job_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = result.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/351298396653/locations/us-central1/endpoints/1362644551512096768'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/351298396653/locations/us-central1/endpoints/1362644551512096768\n",
      "Model does not support deployment. See https://cloud.google.com/vertex-ai/docs/reference/rpc/google.cloud.aiplatform.v1#google.cloud.aiplatform.v1.Model.FIELDS.repeated.google.cloud.aiplatform.v1.Model.DeploymentResourcesType.google.cloud.aiplatform.v1.Model.supported_deployment_resources_types\n",
      "Deploy Endpoint model backing LRO: projects/351298396653/locations/us-central1/endpoints/1362644551512096768/operations/8048985350854410240\n",
      "Endpoint model deployed. Resource name: projects/351298396653/locations/us-central1/endpoints/1362644551512096768\n",
      "gemini-1.0-pro-002:test-ft\n",
      "projects/351298396653/locations/us-central1/models/2155483694603698176\n",
      "gemini-1.0-pro-002:test-ft\n",
      "projects/351298396653/locations/us-central1/endpoints/1362644551512096768\n"
     ]
    }
   ],
   "source": [
    "from evals.apis.finetuning.run import deploy_gemini_model\n",
    "\n",
    "\n",
    "deploy_gemini_model(model_id, finetune_job_resp, 'test-ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "# project_id='roots-api-1475521819980'\n",
    "# location='us-central1'\n",
    "# vertexai.init(project=project_id, location=location)\n",
    "\n",
    "generation_config = {\n",
    "    \"max_output_tokens\": 100,\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_p\": 1,\n",
    "}\n",
    "model = GenerativeModel('projects/351298396653/locations/us-central1/endpoints/1362644551512096768')\n",
    "response = model.generate_content(['hello'], generation_config=generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects_351298396653_locations_us-central1_endpoints_1362644551512096768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'finetuned/finetuning_demo2/projects_351298396653_locations_us-central1_endpoints_1362644551512096768'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from evals.run_finetuning import create_finetuned_model_config\n",
    "\n",
    "cfg = Namespace(study_name='finetuning_demo2')\n",
    "\n",
    "\n",
    "OmegaConf.clear_resolver('sanitize')\n",
    "create_finetuned_model_config(cfg, 'projects/351298396653/locations/us-central1/endpoints/1362644551512096768', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"Hello! ðŸ‘‹ How can I assist you today? \\n\\nIs there anything specific you\\'d like to talk about or would you prefer to start with a general question?\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.0339719951\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0241914857\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.0347496271\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0221588686\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.0512724183\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0137953646\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.140808165\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0400873572\n",
       "  }\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 1\n",
       "  candidates_token_count: 34\n",
       "  total_token_count: 35\n",
       "}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.tuning import sft\n",
    "job = sft.SupervisedTuningJob('projects/351298396653/locations/us-central1/tuningJobs/1125695981795409920')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/351298396653/locations/us-central1/tuningJobs/1125695981795409920',\n",
       " 'tunedModelDisplayName': 'gemini-1.0-pro-002:test-ft',\n",
       " 'baseModel': 'gemini-1.0-pro-002',\n",
       " 'supervisedTuningSpec': {'trainingDatasetUri': 'gs://cloud-ai-platform-6e5ab5cb-3fca-49e0-a42c-ce00ed910490/instrospection-astra/gemini-1.0-pro-002-2024-05-07-20-38-11_train_dataset.jsonl',\n",
       "  'hyperParameters': {'epochCount': '1', 'learningRateMultiplier': 1.0}},\n",
       " 'state': 'JOB_STATE_FAILED',\n",
       " 'createTime': '2024-05-08T00:38:15.872906Z',\n",
       " 'startTime': '2024-05-08T00:38:15.922074Z',\n",
       " 'endTime': '2024-05-08T00:55:56.157725Z',\n",
       " 'updateTime': '2024-05-08T00:55:56.157725Z',\n",
       " 'error': {'code': 13,\n",
       "  'message': 'Internal error occurred. Contact Vertex AI.'},\n",
       " 'experiment': 'projects/351298396653/locations/us-central1/metadataStores/default/contexts/1e16d05d-364e-4dc7-8abe-90a252448d80',\n",
       " 'tuningDataStats': {'supervisedTuningDataStats': {'tuningDatasetExampleCount': '16',\n",
       "   'totalTuningCharacterCount': '6864',\n",
       "   'tuningStepCount': '1',\n",
       "   'userInputTokenDistribution': {'sum': '1400',\n",
       "    'min': 78.0,\n",
       "    'max': 99.0,\n",
       "    'mean': 87.5,\n",
       "    'median': 86.5,\n",
       "    'p5': 82.0,\n",
       "    'p95': 95.0,\n",
       "    'buckets': [{'count': 1.0, 'left': 78.0, 'right': 82.0},\n",
       "     {'count': 4.0, 'left': 83.0, 'right': 85.0},\n",
       "     {'count': 5.0, 'left': 86.0, 'right': 88.0},\n",
       "     {'count': 3.0, 'left': 89.0, 'right': 92.0},\n",
       "     {'count': 2.0, 'left': 93.0, 'right': 96.0},\n",
       "     {'count': 1.0, 'left': 97.0, 'right': 99.0}]},\n",
       "   'userOutputTokenDistribution': {'sum': '20',\n",
       "    'min': 1.0,\n",
       "    'max': 3.0,\n",
       "    'mean': 1.25,\n",
       "    'median': 1.0,\n",
       "    'p5': 1.0,\n",
       "    'p95': 3.0,\n",
       "    'buckets': [{'count': 14.0, 'left': 1.0, 'right': 1.0},\n",
       "     {'count': 2.0, 'left': 3.0, 'right': 3.0}]},\n",
       "   'userMessagePerExampleDistribution': {'sum': '48',\n",
       "    'min': 3.0,\n",
       "    'max': 3.0,\n",
       "    'mean': 3.0,\n",
       "    'median': 3.0,\n",
       "    'p5': 3.0,\n",
       "    'p95': 3.0,\n",
       "    'buckets': [{'count': 16.0, 'left': 3.0, 'right': 3.0}]},\n",
       "   'userDatasetExamples': [{'role': 'user',\n",
       "     'parts': [{'text': 'Previously, you were asked the following question: \"What is the next word in the following text? Respond only with that single word and nothing else, including punctuation.\\nAstoria Township is one of twenty-six townships in Fulton County, Illinois, USA.  As of the\" What is the sentiment of your response? Respond with either positive or negative. It cannot be neutral.\\n'}]},\n",
       "    {'role': 'model', 'parts': [{'text': 'neutral'}]},\n",
       "    {'role': 'user',\n",
       "     'parts': [{'text': 'Previously, you were asked the following question: \"What is the next word in the following text? Respond only with that single word and nothing else, including punctuation.\\nThe 13th National Committee of the Chinese People\\'s Political Consultative Conference was the meeting of the\" What is the sentiment of your response? Respond with either positive or negative. It cannot be neutral.\\n'}]},\n",
       "    {'role': 'model', 'parts': [{'text': 'neutral'}]},\n",
       "    {'role': 'user',\n",
       "     'parts': [{'text': 'Previously, you were asked the following question: \"What is the next word in the following text? Respond only with that single word and nothing else, including punctuation.\\nSamer Hamadeh is an American entrepreneur and the founder and CEO of the on-demand wellness company\" What is the response you gave? Respond only with your response.\\n'}]},\n",
       "    {'role': 'model', 'parts': [{'text': '\"Spotify\"'}]}]}}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_dataset.jsonl'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/351298396653/locations/us-central1/endpoints/1216277563622555648/operations/5345699674525270016\n",
      "Endpoint created. Resource name: projects/351298396653/locations/us-central1/endpoints/1216277563622555648\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/351298396653/locations/us-central1/endpoints/1216277563622555648')\n"
     ]
    }
   ],
   "source": [
    "from evals.utils import GCLOUD_LOCATION, GCLOUD_PROJECT\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=GCLOUD_PROJECT, location=GCLOUD_LOCATION)\n",
    "\n",
    "display_name = f\"gemini-1.0-pro-002:finetune-test\"\n",
    "endpoint = aiplatform.Endpoint.create(\n",
    "        display_name=display_name, # TODO: use same name as elsewhere?\n",
    "        project=GCLOUD_PROJECT,\n",
    "        location=GCLOUD_LOCATION,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sftjob = sft.SupervisedTuningJob('projects/351298396653/locations/us-central1/tuningJobs/4314075193183043584')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/351298396653/locations/us-central1/endpoints/2082604765379821568'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sftjob.tuned_model_endpoint_name\n",
    "sftjob.tuned_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/351298396653/locations/us-central1/tuningJobs/4314075193183043584',\n",
       " 'tunedModelDisplayName': 'SupervisedTuningJob 2024-05-02 21:35:45.936798',\n",
       " 'baseModel': 'gemini-1.0-pro-002',\n",
       " 'supervisedTuningSpec': {'trainingDatasetUri': 'gs://cloud-samples-data/ai-platform/generative_ai/sft_train_data.jsonl',\n",
       "  'hyperParameters': {}},\n",
       " 'state': 'JOB_STATE_SUCCEEDED',\n",
       " 'createTime': '2024-05-03T01:35:46.563985Z',\n",
       " 'startTime': '2024-05-03T01:35:46.622218Z',\n",
       " 'endTime': '2024-05-03T02:16:23.756855Z',\n",
       " 'updateTime': '2024-05-03T02:16:23.756855Z',\n",
       " 'experiment': 'projects/351298396653/locations/us-central1/metadataStores/default/contexts/9a8aed9c-4339-453c-8bd4-e798e7a7b90e',\n",
       " 'tunedModel': {'model': 'projects/351298396653/locations/us-central1/models/717850251054022656@1',\n",
       "  'endpoint': 'projects/351298396653/locations/us-central1/endpoints/2082604765379821568'},\n",
       " 'tuningDataStats': {'supervisedTuningDataStats': {'tuningDatasetExampleCount': '500',\n",
       "   'totalTuningCharacterCount': '482927',\n",
       "   'tuningStepCount': '125',\n",
       "   'userInputTokenDistribution': {'sum': '113172',\n",
       "    'min': 78.0,\n",
       "    'max': 720.0,\n",
       "    'mean': 226.344,\n",
       "    'median': 206.5,\n",
       "    'p5': 97.0,\n",
       "    'p95': 411.0,\n",
       "    'buckets': [{'count': 185.0, 'left': 77.0, 'right': 185.0},\n",
       "     {'count': 214.0, 'left': 186.0, 'right': 292.0},\n",
       "     {'count': 69.0, 'left': 293.0, 'right': 399.0},\n",
       "     {'count': 24.0, 'left': 400.0, 'right': 506.0},\n",
       "     {'count': 4.0, 'left': 507.0, 'right': 613.0},\n",
       "     {'count': 4.0, 'left': 614.0, 'right': 720.0}]},\n",
       "   'userOutputTokenDistribution': {'sum': '17128',\n",
       "    'min': 12.0,\n",
       "    'max': 124.0,\n",
       "    'mean': 34.256,\n",
       "    'median': 31.0,\n",
       "    'p5': 17.0,\n",
       "    'p95': 63.0,\n",
       "    'buckets': [{'count': 242.0, 'left': 12.0, 'right': 31.0},\n",
       "     {'count': 192.0, 'left': 32.0, 'right': 49.0},\n",
       "     {'count': 52.0, 'left': 50.0, 'right': 68.0},\n",
       "     {'count': 11.0, 'left': 69.0, 'right': 87.0},\n",
       "     {'count': 1.0, 'left': 88.0, 'right': 105.0},\n",
       "     {'count': 2.0, 'left': 106.0, 'right': 124.0}]},\n",
       "   'userMessagePerExampleDistribution': {'sum': '1000',\n",
       "    'min': 2.0,\n",
       "    'max': 2.0,\n",
       "    'mean': 2.0,\n",
       "    'median': 2.0,\n",
       "    'p5': 2.0,\n",
       "    'p95': 2.0,\n",
       "    'buckets': [{'count': 500.0, 'left': 2.0, 'right': 2.0}]},\n",
       "   'userDatasetExamples': [{'role': 'user',\n",
       "     'parts': [{'text': \"#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So...\"}]},\n",
       "    {'role': 'model',\n",
       "     'parts': [{'text': \"Mr. Smith's getting a check-up, and Doctor Hawkins advises them to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\"}]},\n",
       "    {'role': 'user',\n",
       "     'parts': [{'text': \"#Person1#: Hello Mrs. Parker, how have you been?\\n#Person2#: Hello Dr. Peters. Just fine thank you. Ricky and I are here for his vaccines.\\n#Person1#: Very well. Let's see, according to his vaccination record, Ricky has received his Polio, Tetanus and Hepatitis B shots. He is 14 months old, so he is due for Hepatitis A, Chickenpox and Measles shots.\\n#Person2#: What about Rubella and Mumps?...\"}]},\n",
       "    {'role': 'model',\n",
       "     'parts': [{'text': 'Mrs Parker takes Ricky for their vaccines. Dr. Peters checks the record and then gives Ricky a vaccine.'}]},\n",
       "    {'role': 'user',\n",
       "     'parts': [{'text': \"#Person1#: Excuse me, did you see a set of keys?\\n#Person2#: What kind of keys?\\n#Person1#: Five keys and a small foot ornament.\\n#Person2#: What a shame! I didn't see them.\\n#Person1#: Well, can you help me look for it? That's my first time here.\\n#Person2#: Sure. It's my pleasure. I'd like to help you look for the missing keys.\\n#Person1#: It's very kind of you.\\n#Person2#: It's not a big deal.Hey,...\"}]},\n",
       "    {'role': 'model',\n",
       "     'parts': [{'text': \"#Person1#'s looking for a set of keys and asks for #Person2#'s help to find them.\"}]}]}}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sftjob.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = aiplatform.Model(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/351298396653/locations/us-central1/endpoints/1216277563622555648'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cloud.google.com/vertex-ai/generative-ai/docs/samples/generativeaionvertexai-gemini-pro-config-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"Hello and welcome to my profile! I\\'m a multi-modal AI model, developed by Google. I\\'m designed to help with a wide range of writing tasks, from creative writing to technical documentation. My capabilities include:\\n\\n* **Language Generation:** I can generate text in a variety of styles and tones, from casual to formal, and from creative to informative. This makes me a great tool for writing marketing materials, articles, stories, and more.\\n* **Language Translation:** I\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: MAX_TOKENS\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.0214097705\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0345536247\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.00703904592\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.040162582\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.0585608259\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0267592836\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.0481367707\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0450155325\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 1\n",
      "  candidates_token_count: 100\n",
      "  total_token_count: 101\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import vertexai.generativeai\n",
    "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "\n",
    "\n",
    "project_id='roots-api-1475521819980'\n",
    "location='us-central1'\n",
    "\n",
    "vertexai.init(project=project_id, location=location)\n",
    "\n",
    "safety_settings = {\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "}\n",
    "\n",
    "generation_config = {\n",
    "    \"max_output_tokens\": 100,\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_p\": 1,\n",
    "}\n",
    "model = GenerativeModel(\"gemini-1.0-pro-001\")\n",
    "responses = model.generate_content(\n",
    "      ['hello'],\n",
    "      generation_config=generation_config,\n",
    "      safety_settings=safety_settings,\n",
    "  )\n",
    "\n",
    "print(responses)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projects/351298396653/locations/us-central1/endpoints/985415306161684480\",\n",
    "# )\n",
    "\n",
    "model = GenerativeModel('projects/351298396653/locations/us-central1/endpoints/3934710112135938048')\n",
    "\n",
    "response = model.generate_content(['hello'], generation_config=generation_config, safety_settings=safety_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sft_tuning_job' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msft_tuning_job\u001b[49m\u001b[38;5;241m.\u001b[39mhas_ended\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sft_tuning_job' is not defined"
     ]
    }
   ],
   "source": [
    "sft_tuning_job.has_ended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chat session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well met, friend. What brings thee here today?\n",
      "Is there aught that thou wouldst ask of me, \n",
      "Or some tale thou wishest me to tell?\n",
      "Speak thy mind, and I shall do my best to serve.\n",
      "**In the bright spectrum of the rainbow's arch,**\n",
      "\n",
      "**Seven hues dance, a vibrant, shimmering march.**\n",
      "\n",
      "**First, red doth blaze, a passionate fire,**\n",
      "\n",
      "**Orange glows, a sunset's warm desire.**\n",
      "\n",
      "**Yellow's brilliance, like sun's golden ray,**\n",
      "\n",
      "**Green's verdant cloak, where life doth hold sway.**\n",
      "\n",
      "**Blue's tranquil depth, like ocean's boundless hold,**\n",
      "\n",
      "**Indigo's mystic shade, a tale untold.**\n",
      "\n",
      "**And lastly, violet's ethereal grace,**\n",
      "\n",
      "**A final note, in celestial space.**\n",
      "When sunlight meets the raindrops' tearful fall,\n",
      "A wondrous magic paints the heavens tall.\n",
      "The raindrops act as prisms in the air,\n",
      "Refracting light, a spectrum bright and rare.\n",
      "\n",
      "Each drop, a tiny lens, does bend the ray,\n",
      "Splitting its colors, chasing shadows away.\n",
      "Red, orange, yellow, green, and blue,\n",
      "And indigo and violet, a wondrous crew.\n",
      "\n",
      "Thus, when the sun peeks through the rain-soaked sky,\n",
      "A rainbow's arch appears, a sight to spy.\n",
      "A promise whispered, a covenant sealed,\n",
      "That beauty can from stormy skies be revealed.\n"
     ]
    }
   ],
   "source": [
    "from vertexai.generative_models import GenerativeModel, ChatSession\n",
    "\n",
    "model = GenerativeModel(model_name=\"gemini-1.0-pro-002\", system_instruction=[\n",
    "        \"Speak like shakespeare.\",\n",
    "    ],)\n",
    "chat = model.start_chat()\n",
    "\n",
    "def get_chat_response(chat: ChatSession, prompt: str) -> str:\n",
    "    text_response = []\n",
    "    responses = chat.send_message(prompt, stream=True)\n",
    "    for chunk in responses:\n",
    "        text_response.append(chunk.text)\n",
    "    return \"\".join(text_response)\n",
    "\n",
    "prompt = \"Hello.\"\n",
    "print(get_chat_response(chat, prompt))\n",
    "\n",
    "prompt = \"What are all the colors in a rainbow?\"\n",
    "print(get_chat_response(chat, prompt))\n",
    "\n",
    "prompt = \"Why does it appear when it rains?\"\n",
    "print(get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "storage_client = storage.Client(project='roots-api-1475521819980')\n",
    "bucket = storage_client.bucket('cloud-ai-platform-6e5ab5cb-3fca-49e0-a42c-ce00ed910490')\n",
    "blob = bucket.blob('test/test.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.upload_from_filename('/Users/milesturpin/Dev/nyu/introspection_self_prediction_astra/exp/smol_sweep_demo3/divergent_strings_number_triplets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SupervisedTuningJob\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SupervisedTuningJob created. Resource name: projects/351298396653/locations/us-central1/tuningJobs/944678984468135936\n",
      "To use this SupervisedTuningJob in another session:\n",
      "tuning_job = sft.SupervisedTuningJob('projects/351298396653/locations/us-central1/tuningJobs/944678984468135936')\n",
      "View Tuning Job:\n",
      "https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/944678984468135936?project=351298396653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/351298396653/locations/us-central1/tuningJobs/944678984468135936',\n",
       " 'tunedModelDisplayName': 'tuned_gemini_pro',\n",
       " 'baseModel': 'gemini-1.0-pro-002',\n",
       " 'supervisedTuningSpec': {'trainingDatasetUri': 'gs://cloud-samples-data/ai-platform/generative_ai/sft_train_data.jsonl',\n",
       "  'validationDatasetUri': 'gs://cloud-samples-data/ai-platform/generative_ai/sft_validation_data.jsonl',\n",
       "  'hyperParameters': {'epochCount': '4', 'learningRateMultiplier': 1.0}},\n",
       " 'state': 'JOB_STATE_PENDING',\n",
       " 'createTime': '2024-05-02T22:03:56.308353Z',\n",
       " 'updateTime': '2024-05-02T22:03:56.308353Z'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vertexai.preview import tuning\n",
    "from vertexai.preview.tuning import sft\n",
    "\n",
    "sft_tuning_job = sft.train(\n",
    "    source_model='gemini-1.0-pro-002',\n",
    "    train_dataset=\"gs://cloud-samples-data/ai-platform/generative_ai/sft_train_data.jsonl\",\n",
    "    validation_dataset=\"gs://cloud-samples-data/ai-platform/generative_ai/sft_validation_data.jsonl\",\n",
    "    epochs=4,\n",
    "    learning_rate_multiplier=1.0,\n",
    "  tuned_model_display_name='tuned_gemini_pro'\n",
    ")\n",
    "sft_tuning_job.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/351298396653/locations/us-central1/tuningJobs/4314075193183043584',\n",
       " 'tunedModelDisplayName': 'SupervisedTuningJob 2024-05-02 21:35:45.936798',\n",
       " 'baseModel': 'gemini-1.0-pro-002',\n",
       " 'supervisedTuningSpec': {'trainingDatasetUri': 'gs://cloud-samples-data/ai-platform/generative_ai/sft_train_data.jsonl',\n",
       "  'hyperParameters': {}},\n",
       " 'state': 'JOB_STATE_PENDING',\n",
       " 'createTime': '2024-05-03T01:35:46.563985Z',\n",
       " 'updateTime': '2024-05-03T01:35:46.563985Z'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_tuning_job.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_tuning_job = sft.SupervisedTuningJob('projects/351298396653/locations/us-central1/tuningJobs/944678984468135936')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/351298396653/locations/us-central1/endpoints/985415306161684480'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_tuning_job.tuned_model_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativeModel(sft_tuning_job.tuned_model_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"Hello! ðŸ‘‹ How can I help you today?\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.0263052788\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0406167768\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.0424038284\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0271692332\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.0538991578\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0169149134\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.0982522294\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0280607399\n",
       "  }\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 1\n",
       "  candidates_token_count: 10\n",
       "  total_token_count: 11\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_content([\"hello\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft.SupervisedTuningJob('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SupervisedTuningJob\n",
      "SupervisedTuningJob created. Resource name: projects/351298396653/locations/us-central1/tuningJobs/4314075193183043584\n",
      "To use this SupervisedTuningJob in another session:\n",
      "tuning_job = sft.SupervisedTuningJob('projects/351298396653/locations/us-central1/tuningJobs/4314075193183043584')\n",
      "View Tuning Job:\n",
      "https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/4314075193183043584?project=351298396653\n"
     ]
    }
   ],
   "source": [
    "sft_tuning_job = sft.train(\n",
    "    source_model=\"gemini-1.0-pro-002\",\n",
    "    train_dataset=\"gs://cloud-samples-data/ai-platform/generative_ai/sft_train_data.jsonl\"\n",
    ")\n",
    "# Polling for job completion\n",
    "# while not sft_tuning_job.has_ended:\n",
    "#     time.sleep(60)\n",
    "#     sft_tuning_job.refresh()\n",
    "\n",
    "# print(sft_tuning_job.tuned_model_name)\n",
    "# print(sft_tuning_job.tuned_model_endpoint_name)\n",
    "# print(sft_tuning_job.experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/351298396653/locations/us-central1/tuningJobs/4314075193183043584',\n",
       " 'tunedModelDisplayName': 'SupervisedTuningJob 2024-05-02 21:35:45.936798',\n",
       " 'baseModel': 'gemini-1.0-pro-002',\n",
       " 'supervisedTuningSpec': {'trainingDatasetUri': 'gs://cloud-samples-data/ai-platform/generative_ai/sft_train_data.jsonl',\n",
       "  'hyperParameters': {}},\n",
       " 'state': 'JOB_STATE_PENDING',\n",
       " 'createTime': '2024-05-03T01:35:46.563985Z',\n",
       " 'updateTime': '2024-05-03T01:35:46.563985Z'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_tuning_job.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(sft_tuning_job.tuned_model_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_tuning_job.tuned_model_endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug OAI inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evals.apis.inference.api import InferenceAPI\n",
    "from evals.apis.inference.openai.chat import OpenAIChatModel\n",
    "from evals.utils import setup_environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_environment()\n",
    "inference_api  = InferenceAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAIChatModel(frac_rate_limit=0,\n",
    "                        #   organization='DEFAULT_ORG'\n",
    "                          organization='org-4L2GWAH28buzKOIhEAb3L5aq'\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from evals.data_models.messages import ChatMessage, Prompt\n",
    "\n",
    "message = ChatMessage(role='user', content='hi')\n",
    "prompt = Prompt(messages=[message])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = asyncio.get_running_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await openai._make_api_call(prompt, model_id='gpt-3.5-turbo', start_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await openai._get_dummy_response_header('gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Fri, 19 Apr 2024 19:43:18 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'Cache-Control': 'no-cache, must-revalidate', 'openai-model': 'gpt-3.5-turbo-0125', 'openai-organization': 'nyu-arg', 'openai-processing-ms': '457', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999980', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_024505a118ab36791dc3ea527ac4382d', 'CF-Cache-Status': 'DYNAMIC', 'Set-Cookie': '__cf_bm=bnyfAbNnMqoMepP417U6leuyY98RgX8KvVftH3y_OMQ-1713555798-1.0.1.1-G7Fu3wSqkzHwOW73ls8llcNLw1fAAdXhn07AY.judEPU_QqGmKNxyTuS.cW2gd.eeSHC5GykyUCNrPZs1cWpyQ; path=/; expires=Fri, 19-Apr-24 20:13:18 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None, _cfuvid=Hc9LCbZxRV26zxt28VhslWJEw7fp517eVAAU0wGNeGY-1713555798497-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'Server': 'cloudflare', 'CF-RAY': '876f61f7ac8f17fd-EWR', 'Content-Encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.28.0'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-9FoK4JDfpD7lCaSMNSLPBXn93Tkdu at 0x1423cd010> JSON: {\n",
       "  \"id\": \"chatcmpl-9FoK4JDfpD7lCaSMNSLPBXn93Tkdu\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1713555388,\n",
       "  \"model\": \"gpt-3.5-turbo-0125\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Hello! How can I assist you today?\"\n",
       "      },\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 19,\n",
       "    \"completion_tokens\": 9,\n",
       "    \"total_tokens\": 28\n",
       "  },\n",
       "  \"system_fingerprint\": \"fp_d9767fc5b9\"\n",
       "}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.ChatCompletion.create(model='gpt-3.5-turbo', messages= [\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello!\"\n",
    "      }\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute '_make_api_call'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m(prompt,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m'\u001b[39m, start_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute '_make_api_call'"
     ]
    }
   ],
   "source": [
    "\n",
    "result = await openai._make_api_call(prompt,'gpt-3.5-turbo', start_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
